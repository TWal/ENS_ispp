\documentclass[12pt]{article}

\input{init.tex}


\usepackage[bottom=2cm,left=2cm,right=2cm,top=2cm]{geometry}

\title{Automated methods for optimizing cache on algebraic data structure}

\author{Thibaut Pérami, Théophile Wallez and Luc Chabassier}


\begin{document}

\maketitle


\section{Abstract}

The speed of modern processors is nearly entirely determined by RAM access and
especially the number of cache misses. Lots of widely used data structures are
quite cache-friendly : array, matrices, but others like linked list, tree or
more complex construction with sum and product data types are far more difficult to
optimize.

In this paper we try to implement automated code generation of cache optimized
representation of algebraic data types depending of the concrete algorithm
implemented. Currently most functional compilers implement algebraic data type with
lot of pointers and dispersed pieces of data across the RAM (depending on the
garbage collector implementation). We try to create parametric implementations
of compacted representation of these structures and to tune them automatically
depending on the input algorithm.

\section{Cache and complex structures}

\subsection{Cache Structure}

TODO : blabla à propos des niveaux des caches du temps d'accès des modèles de
caches utilisé ...

\subsection{Model used}

\subsection{DAG structure}

\subsection{Objectives}

Our objective is to show how from a simple input : a description of an algebraic
data type and a programming code using them.

Currently our test code takes an algebraic data type with a simple format :

\verb$ type tree = | Node tree tree | Leaf$

And the code can be used in the following way:

...

From that, we first compile against a naive implementation of the algebraic data type
and execute it. This version also logs all construction/deconstruction operations by
numbering all variables and write a file like :

\verb$107 < (12,56,78)$

We can then analyze this trace of execution and extract statistics from it (cf.\ 
section \ref{logs}). From
those statistics we try to deduce the most optimal way to encode it in memory by
tuning the input value of some parametric structures (cf.\ section \ref{paramImplem})




\section{Naive Implementation}

The naive implementation of algebraic data type consists in using different memory
block for every node: data is dispersed in RAM and blocks have pointers to
other blocks.



\section{Parametric Implementation}
\label{paramImplem}

As we can't (or its completely out of our reach) write code
depending on the input, we have chosen to write ``parametric code'' : code that
depends on some integer/real parameters and we just try to automatically tweak
those parameters depending of the input code.

\subsection{Block allocation}

This method is a simple idea to gather data close together. We regroup data in
blocks and blocks on other blocks. We define $N +1$ levels of blocks from 0 to
$N$. The level $0$ stores elementary structure, level $0$ blocks are just blocks of
data with no structure.

For each other level $i$, we store block of size $i-1$, At each level we define
$\alpha_i$ the minimum ratio of $i-1$ blocks.


\paragraph{TODO :} Fusion and split algorithm, other meta-data description (link
with other blocks)




\subsection{Compact trees \& pointer elimination}







\section{Possible Analysis on execution traces}
\label{logs}

\subsection{Execution logs}

\subsection{Statistics}

\section{Experimental Results}



\section{Conclusion}






\end{document}
